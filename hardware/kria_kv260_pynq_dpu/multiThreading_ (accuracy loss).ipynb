{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPU example: Resnet50\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the overlay\n",
    "We will download the overlay onto the board. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility functions\n",
    "\n",
    "In this section, we will prepare a few functions for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"kv260_tipu12.xmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define a few useful preprocessing functions. These functions\n",
    "will make sure the DPU can take input images with arbitrary sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_R_MEAN = 123.68\n",
    "_G_MEAN = 116.78\n",
    "_B_MEAN = 103.94\n",
    "\n",
    "MEANS = [_B_MEAN,_G_MEAN,_R_MEAN]\n",
    "\n",
    "def resize_shortest_edge(image, size):\n",
    "    H, W = image.shape[:2]\n",
    "    if H >= W:\n",
    "        nW = size\n",
    "        nH = int(float(H)/W * size)\n",
    "    else:\n",
    "        nH = size\n",
    "        nW = int(float(W)/H * size)\n",
    "    return cv2.resize(image,(nW,nH))\n",
    "\n",
    "def mean_image_subtraction(image, means):\n",
    "    B, G, R = cv2.split(image)\n",
    "    B = B - means[0]\n",
    "    G = G - means[1]\n",
    "    R = R - means[2]\n",
    "    image = cv2.merge([R, G, B])\n",
    "    return image\n",
    "\n",
    "def BGR2RGB(image):\n",
    "    B, G, R = cv2.split(image)\n",
    "    image = cv2.merge([R, G, B])\n",
    "    return image\n",
    "\n",
    "def central_crop(image, crop_height, crop_width):\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    offset_height = (image_height - crop_height) // 2\n",
    "    offset_width = (image_width - crop_width) // 2\n",
    "    return image[offset_height:offset_height + crop_height, offset_width:\n",
    "                 offset_width + crop_width, :]\n",
    "\n",
    "def normalize(image):\n",
    "    image=image/256.0\n",
    "    image=image-0.5\n",
    "    image=image*2\n",
    "    return image\n",
    "\n",
    "def preprocess_fn(image, image_path, crop_height = 224, crop_width = 224):\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Error reading image at {image_path}\")\n",
    "    image = resize_shortest_edge(image, 256)\n",
    "    #image = mean_image_subtraction(image, MEANS)\n",
    "    image = central_crop(image, crop_height, crop_width)\n",
    "    image = BGR2RGB(image)\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also define a few functions to calculate softmax and provide \n",
    "the output class after running a DPU task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_softmax(data):\n",
    "    e_x = np.exp(data - np.max(data))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def predict_label(softmax):\n",
    "    with open(\"class_to_order.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [item.strip() for item in lines]\n",
    "        class_arg = np.argmax(softmax)\n",
    "        class_name = lines[class_arg]\n",
    "    return class_name, class_arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that our original images are 640x480 so we need to preprocess them\n",
    "later to make sure it fits our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use VART\n",
    "Now we should be able to use VART to do image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpu = overlay.runner\n",
    "\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "shapeOut = tuple(outputTensors[0].dims)\n",
    "outputSize = int(outputTensors[0].get_data_size() / shapeIn[0])\n",
    "\n",
    "softmax = np.empty(outputSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a few buffers to store input and output data. They will be reused\n",
    "during multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_images(dataset_folder):\n",
    "    total = 0\n",
    "    for class_folder in os.listdir(dataset_folder):\n",
    "        class_path = os.path.join(dataset_folder, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            total += len(os.listdir(class_path))\n",
    "    return total\n",
    "\n",
    "def is_image_file(file_path):\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    return ext in valid_extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we have a list of `original_images`. \n",
    "We can now define a new function `run()` which takes the image index as \n",
    "the input, and calculate the softmax as the classification result.\n",
    "With the argument `display` set to `True`, the original image as well as the\n",
    "predicted label can be rendered.\n",
    "\n",
    "It is obvious that the range of `image_index` should be [0, `total_images`-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 3232 images: 56.31 seconds\n",
      "FPS: 57.40\n",
      "Correct predictions: 2332\n",
      "Accuracy: 0.7215346534653465\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import Queue\n",
    "import time\n",
    "\n",
    "# Define a queue for image paths to be processed\n",
    "image_queue = Queue()\n",
    "\n",
    "correct = 0  # Global variable for correct predictions\n",
    "labels = []\n",
    "labels_in_correct_order = []\n",
    "predictions_list = []\n",
    "index = 0\n",
    "\n",
    "# Lock for synchronization\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Function to perform inference on images\n",
    "def inference_worker():\n",
    "    global correct\n",
    "    global index\n",
    "    while True:\n",
    "        image_path = image_queue.get()\n",
    "        if image_path is None:\n",
    "            break\n",
    "        if not is_image_file(image_path):\n",
    "            #print(f\"Skipping non-image file: {image_path}\")\n",
    "            continue\n",
    "            \n",
    "        with lock:\n",
    "            current_index = index\n",
    "            index += 1\n",
    "        \n",
    "        preprocessed_image = preprocess_fn(cv2.imread(image_path), image_path)\n",
    "        image[0,...] = preprocessed_image.reshape(shapeIn[1:])\n",
    "        \n",
    "        job_id = dpu.execute_async(input_data, output_data)\n",
    "        dpu.wait(job_id)\n",
    "        \n",
    "        temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "        softmax = calculate_softmax(temp[0][0])\n",
    "        predicted_label = predict_label(softmax)\n",
    "        \n",
    "        with lock:\n",
    "            predictions_list.append(predicted_label[0])\n",
    "            labels_in_correct_order.append(labels[current_index])\n",
    "            if predicted_label[0] == labels[current_index]:\n",
    "                correct += 1\n",
    "        \n",
    "        image_queue.task_done()\n",
    "\n",
    "# Number of threads\n",
    "num_threads = 4  # Adjust based on system resources and performance\n",
    "\n",
    "# Start threads\n",
    "threads = []\n",
    "for _ in range(num_threads):\n",
    "    t = threading.Thread(target=inference_worker)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "image_folder = \"test_tipu12/test\"    \n",
    "\n",
    "# Queue up image paths for processing\n",
    "for class_folder in os.listdir(image_folder):\n",
    "    class_path = os.path.join(image_folder, class_folder)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    for image_name in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_name)\n",
    "        if not is_image_file(image_path):\n",
    "            continue\n",
    "        image_queue.put(image_path)\n",
    "        labels.append(class_folder)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Wait for all threads to complete processing\n",
    "image_queue.join()\n",
    "\n",
    "# Stop threads by sending None to the queue\n",
    "for _ in range(num_threads):\n",
    "    image_queue.put(None)\n",
    "\n",
    "# Join threads\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# Calculate FPS\n",
    "total_images = count_total_images(image_folder)\n",
    "total_time = time.time() - start_time\n",
    "fps = total_images / total_time\n",
    "\n",
    "print(f\"Total time for {total_images} images: {total_time:.2f} seconds\")\n",
    "print(f\"FPS: {fps:.2f}\")\n",
    "print(f\"Correct predictions: {correct}\")\n",
    "print(f\"Accuracy: {correct/len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_mean: 0.7191153930350014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def confusion_matrix_stats(conf_mat):\n",
    "    # Counting true positives, false positives, true negatives, and false negatives\n",
    "    true_positives = np.diag(conf_mat)\n",
    "    false_positives = np.sum(conf_mat, axis=1) - true_positives\n",
    "    false_negatives = np.sum(conf_mat, axis=0) - true_positives\n",
    "    true_negatives = np.sum(conf_mat) - true_positives - false_positives - false_negatives\n",
    "    # F1 Score\n",
    "    f1_score = np.where((true_positives + false_positives + false_negatives) > 0, 2 * true_positives / (2 * true_positives + false_positives + false_negatives), 0)\n",
    "    return f1_score, true_positives, false_positives, false_negatives, true_negatives\n",
    "\n",
    "labels.reverse()\n",
    "conf_mat = confusion_matrix(labels_in_correct_order, predictions_list)\n",
    "\n",
    "f1_score, true_positives, false_positives, false_negatives, true_negatives = confusion_matrix_stats(conf_mat)\n",
    "\n",
    "f1_score_mean = np.mean(f1_score[:])\n",
    "\n",
    "print(f\"f1_score_mean: {f1_score_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will need to remove references to `vart.Runner` and let Python garbage-collect\n",
    "the unused graph objects. This will make sure we can run other notebooks without\n",
    "any issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del overlay\n",
    "del dpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Copyright (C) 2021 Xilinx, Inc\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0 License\n",
    "\n",
    "----\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
